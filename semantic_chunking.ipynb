{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import sec_parser as sp\n",
    "from sec_parser import (\n",
    "    Edgar10QParser,\n",
    "    TitleElement,\n",
    "    TextElement,\n",
    "    TopSectionTitle,\n",
    ")\n",
    "import sec_downloader as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sec_parser import Edgar10QParser, TreeBuilder\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the breakpoint percentile threshold\n",
    "breakpoint_percentile_threshold = 95  # set up the initial threshold value\n",
    "chunk_size_ceiling = 2000\n",
    "\n",
    "# extract all the text (excluding tables), convert to Markdown format\n",
    "def convert_to_markdown(sections,level_to_markdown):\n",
    "    markdown = \"\"\n",
    "    for section in sections:\n",
    "        if isinstance(section.semantic_element, (TopSectionTitle, TitleElement)):\n",
    "            markdown += f\"{level_to_markdown.get(section.semantic_element.level, '#')} {section.semantic_element.text}\\n\"\n",
    "        elif isinstance(section.semantic_element, TextElement):\n",
    "            markdown += f\"{section.semantic_element.text}\\n\"\n",
    "        for child in section.get_descendants():\n",
    "            if isinstance(child.semantic_element, (TopSectionTitle, TitleElement)):\n",
    "                markdown += f\"{level_to_markdown.get(child.semantic_element.level, '#')} {child.semantic_element.text}\\n\"\n",
    "            elif isinstance(child.semantic_element, TextElement):\n",
    "                markdown += f\"{child.semantic_element.text}\\n\"\n",
    "    return markdown\n",
    "\n",
    "def combine_sentences(sentences, buffer_size=1):\n",
    "    # Go through each sentence dict\n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        # Create a string that will hold the sentences which are joined\n",
    "        combined_sentence = \"\"\n",
    "\n",
    "        # Add sentences before the current one, based on the buffer size.\n",
    "        for j in range(i - buffer_size, i):\n",
    "            # Check if the index j is not negative (to avoid index out of range like on the first one)\n",
    "            if j >= 0:\n",
    "                # Add the sentence at index j to the combined_sentence string\n",
    "                combined_sentence += sentences[j][\"sentence\"] + \" \"\n",
    "\n",
    "        # Add the current sentence\n",
    "        combined_sentence += sentences[i][\"sentence\"]\n",
    "\n",
    "        # Add sentences after the current one, based on the buffer size\n",
    "        for j in range(i + 1, i + 1 + buffer_size):\n",
    "            # Check if the index j is within the range of the sentences list\n",
    "            if j < len(sentences):\n",
    "                # Add the sentence at index j to the combined_sentence string\n",
    "                combined_sentence += \" \" + sentences[j][\"sentence\"]\n",
    "\n",
    "        # Then add the whole thing to your dict\n",
    "        # Store the combined sentence in the current sentence dict\n",
    "        sentences[i][\"combined_sentence\"] = combined_sentence\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# Function to calculate chunk sizes\n",
    "def calculate_chunk_sizes(sentences, distances, threshold):\n",
    "    # Determine the distance threshold\n",
    "    breakpoint_distance_threshold = np.percentile(distances, threshold)\n",
    "\n",
    "    # Find the indices of distances above the threshold\n",
    "    indices_above_thresh = [\n",
    "        i for i, x in enumerate(distances) if x > breakpoint_distance_threshold\n",
    "    ]\n",
    "\n",
    "    # Initialize the start index\n",
    "    start_index = 0\n",
    "    chunks = []\n",
    "\n",
    "    # Iterate through the breakpoints to slice the sentences\n",
    "    for index in indices_above_thresh:\n",
    "        end_index = index\n",
    "        group = sentences[start_index : end_index + 1]\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in group])\n",
    "        chunks.append(combined_text)\n",
    "        start_index = index + 1\n",
    "\n",
    "    # The last group, if any sentences remain\n",
    "    if start_index < len(sentences):\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in sentences[start_index:]])\n",
    "        chunks.append(combined_text)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Function to find appropriate threshold\n",
    "def find_appropriate_threshold(sentences, distances, initial_threshold, ceiling):\n",
    "    threshold = initial_threshold\n",
    "    while threshold > 0:\n",
    "        chunks = calculate_chunk_sizes(sentences, distances, threshold)\n",
    "        chunk_sizes = [len(chunk.split()) for chunk in chunks]\n",
    "        if max(chunk_sizes) <= ceiling:\n",
    "            break\n",
    "        threshold -= 1\n",
    "    return threshold, chunks, chunk_sizes\n",
    "\n",
    "def calculate_cosine_distances(sentences):\n",
    "    distances = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        embedding_current = sentences[i][\"combined_sentence_embedding\"]\n",
    "        embedding_next = sentences[i + 1][\"combined_sentence_embedding\"]\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([embedding_current], [embedding_next])[0][0]\n",
    "\n",
    "        # Convert to cosine distance\n",
    "        distance = 1 - similarity\n",
    "\n",
    "        # Append cosine distance to the list\n",
    "        distances.append(distance)\n",
    "\n",
    "        # Store distance in the dictionary\n",
    "        sentences[i][\"distance_to_next\"] = distance\n",
    "\n",
    "    # Optionally handle the last sentence\n",
    "    # sentences[-1]['distance_to_next'] = None  # or a default value\n",
    "\n",
    "    return distances, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_financial_document(file_path):\n",
    "    \"\"\"\n",
    "    Processes a financial document, chunks it, and stores the chunks in a FAISS vector store.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the financial document file.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: The FAISS vector store containing the document chunks.\n",
    "    \"\"\"\n",
    "    # Load the environment variables from the .env file\n",
    "\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    # Step 1: Load and parse the financial document\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    parser = Edgar10QParser()\n",
    "    elements = parser.parse(html_content)\n",
    "    \n",
    "    tree_builder = TreeBuilder()\n",
    "    top_level_sections = [\n",
    "        item for part in tree_builder.build(elements) for item in part.children\n",
    "    ]\n",
    "\n",
    "    # get levels\n",
    "    levels = sorted(\n",
    "        {\n",
    "            k.semantic_element.level\n",
    "            for k in top_level_sections\n",
    "            if isinstance(k.semantic_element, (sp.TopSectionTitle, sp.TitleElement))\n",
    "        }\n",
    "    )\n",
    "    level_to_markdown = {level: \"#\" * (i + 2) for i, level in enumerate(levels)}\n",
    "\n",
    "    # extract all the text (excluding tables)\n",
    "    raw_essay = convert_to_markdown(top_level_sections, level_to_markdown)\n",
    "\n",
    "    new_txt_filename = \"file_without_table.txt\"\n",
    "\n",
    "    # Put the extrated content in a new txt file\n",
    "    with open(new_txt_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(raw_essay)\n",
    "\n",
    "    # Read the content we just put in\n",
    "    with open(new_txt_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        essay = file.read()\n",
    "\n",
    "    # Splitting the essay on '.', '#', and ':'\n",
    "    single_sentences_list = re.split(r\"(?<=[.#:])\\s+\", essay)\n",
    "\n",
    "    # Turn this list of sentence into a list of dictionaries for further embedding works\n",
    "    sentences = [{\"sentence\": x, \"index\": i} for i, x in enumerate(single_sentences_list)]\n",
    "\n",
    "    sentences = combine_sentences(sentences)\n",
    "\n",
    "    oaiembeds = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "    # Now let's go get our embeddings. We'll do this in batch to make it quicker.\n",
    "    embeddings = oaiembeds.embed_documents([x[\"combined_sentence\"] for x in sentences])\n",
    "\n",
    "    # add this list of embedding to our list of dicts\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence[\"combined_sentence_embedding\"] = embeddings[i]\n",
    "\n",
    "    # pull out the distances from our sentences and then add them as well\n",
    "\n",
    "    distances, sentences = calculate_cosine_distances(sentences)\n",
    "\n",
    "    # Use the function to find the appropriate threshold\n",
    "    threshold, chunks, chunk_sizes = find_appropriate_threshold(\n",
    "        sentences, distances, breakpoint_percentile_threshold, chunk_size_ceiling\n",
    "    )\n",
    "\n",
    "    print(\"Final threshold used:\", threshold)\n",
    "\n",
    "    # We need to get the distance threshold that we'll consider an outlier\n",
    "    # We'll use numpy .percentile() for this\n",
    "    breakpoint_distance_threshold = np.percentile(distances, threshold)\n",
    "\n",
    "    # Then we'll see how many distances are actually above this one\n",
    "    num_distances_above_theshold = len(\n",
    "        [x for x in distances if x > breakpoint_distance_threshold]\n",
    "    )  # The amount of distances above your threshold\n",
    "\n",
    "    # Then we'll get the index of the distances that are above the threshold. This will tell us where we should split our text\n",
    "    indices_above_thresh = [\n",
    "        i for i, x in enumerate(distances) if x > breakpoint_distance_threshold\n",
    "    ]  # The indices of those breakpoints on your list\n",
    "\n",
    "    # Initialize the start index\n",
    "    start_index = 0\n",
    "    \n",
    "    # Create a list to hold the grouped sentences\n",
    "    chunks = []\n",
    "    \n",
    "    # Iterate through the breakpoints to slice the sentences\n",
    "    for index in indices_above_thresh:\n",
    "        # The end index is the current breakpoint\n",
    "        end_index = index\n",
    "    \n",
    "        # Slice the sentence_dicts from the current start index to the end index\n",
    "        group = sentences[start_index : end_index + 1]\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in group])\n",
    "        chunks.append(combined_text)\n",
    "    \n",
    "        # Update the start index for the next group\n",
    "        start_index = index + 1\n",
    "    \n",
    "    # The last group, if any sentences remain\n",
    "    if start_index < len(sentences):\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in sentences[start_index:]])\n",
    "        chunks.append(combined_text)\n",
    "    \n",
    "    # grouped_sentences now contains the chunked sentences\n",
    "\n",
    "    # `chunks` is a list of strings, we have to convert to page_content for storing\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    embeddings_engine = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    # take embeddings of chunks and store in FAISS vector store\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings_engine)\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item1a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item8. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item10. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item11. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item12. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item13. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item14. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item15. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item16. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final threshold used: 83\n"
     ]
    }
   ],
   "source": [
    "doc_path = r\"data/sec-edgar-filings/AAPL/10-k/2023/primary_document.html\"\n",
    "vs1 = process_financial_document(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the store: 158\n"
     ]
    }
   ],
   "source": [
    "# check how many vectors we have in the store\n",
    "index = vs1.index\n",
    "print(f\"Number of vectors in the store: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 0: [ 0.0025478   0.00010713 -0.00851038 ... -0.0143102  -0.0221363\n",
      " -0.01553261]\n",
      "Vector 1: [ 0.00370047 -0.01104865  0.00202998 ...  0.00796163  0.00790226\n",
      " -0.02796793]\n",
      "Vector 2: [ 0.00859033 -0.00238253  0.01003133 ...  0.01358163 -0.01032371\n",
      " -0.01758441]\n"
     ]
    }
   ],
   "source": [
    "# To look at the first 3 vectors, we can retrieve them using their IDs\n",
    "for i in range(min(3, index.ntotal)):\n",
    "    vector = index.reconstruct(i)\n",
    "    print(f\"Vector {i}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first k relevant documents in the vector store\n",
    "retriever = vs1.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "query = \" How is the Segment Operating Performance of Apple company in Greater China?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "len(docs)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = r\"data\\sec-edgar-filings\\AAPL\\10-q\\2024\\Q1\\primary_document.html\"\n",
    "vs2 = process_financial_document(doc_path)\n",
    "\n",
    "# check how many vectors we have in the store\n",
    "index = vs2.index\n",
    "print(f\"Number of vectors in the store: {index.ntotal}\")\n",
    "\n",
    "# To look at the first 3 vectors, we can retrieve them using their IDs\n",
    "for i in range(min(3, index.ntotal)):\n",
    "    vector = index.reconstruct(i)\n",
    "    print(f\"Vector {i}: {vector}\")\n",
    "\n",
    "# Retrieve the first k relevant documents in the vector store\n",
    "retriever = vs2.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "query = \" How is the Segment Operating Performance of Apple company in Greater China?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "len(docs)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_markdown(sections, level_to_markdown):\n",
    "    markdown = \"\"\n",
    "    for section in sections:\n",
    "        if isinstance(section.semantic_element, (TopSectionTitle, TitleElement)):\n",
    "            markdown += f\"{level_to_markdown.get(section.semantic_element.level, '#')} {section.semantic_element.text}\\n\"\n",
    "        elif isinstance(section.semantic_element, TextElement):\n",
    "            markdown += f\"{section.semantic_element.text}\\n\"\n",
    "        for child in section.get_descendants():\n",
    "            if isinstance(child.semantic_element, (TopSectionTitle, TitleElement)):\n",
    "                markdown += f\"{level_to_markdown.get(child.semantic_element.level, '#')} {child.semantic_element.text}\\n\"\n",
    "            elif isinstance(child.semantic_element, TextElement):\n",
    "                markdown += f\"{child.semantic_element.text}\\n\"\n",
    "    return markdown\n",
    "\n",
    "def combine_sentences(sentences, buffer_size=1):\n",
    "    for i in range(len(sentences)):\n",
    "        combined_sentence = \"\"\n",
    "        for j in range(i - buffer_size, i):\n",
    "            if j >= 0:\n",
    "                combined_sentence += sentences[j][\"sentence\"] + \" \"\n",
    "        combined_sentence += sentences[i][\"sentence\"]\n",
    "        for j in range(i + 1, i + 1 + buffer_size):\n",
    "            if j < len(sentences):\n",
    "                combined_sentence += \" \" + sentences[j][\"sentence\"]\n",
    "        sentences[i][\"combined_sentence\"] = combined_sentence\n",
    "    return sentences\n",
    "\n",
    "def calculate_chunk_sizes(sentences, distances, threshold):\n",
    "    breakpoint_distance_threshold = np.percentile(distances, threshold)\n",
    "    indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]\n",
    "    start_index = 0\n",
    "    chunks = []\n",
    "    for index in indices_above_thresh:\n",
    "        end_index = index\n",
    "        group = sentences[start_index : end_index + 1]\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in group])\n",
    "        chunks.append(combined_text)\n",
    "        start_index = index + 1\n",
    "    if start_index < len(sentences):\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in sentences[start_index:]])\n",
    "        chunks.append(combined_text)\n",
    "    return chunks\n",
    "\n",
    "def find_appropriate_threshold(sentences, distances, initial_threshold, ceiling):\n",
    "    threshold = initial_threshold\n",
    "    while threshold > 0:\n",
    "        chunks = calculate_chunk_sizes(sentences, distances, threshold)\n",
    "        chunk_sizes = [len(chunk.split()) for chunk in chunks]\n",
    "        if max(chunk_sizes) <= ceiling:\n",
    "            break\n",
    "        threshold -= 1\n",
    "    return threshold, chunks, chunk_sizes\n",
    "\n",
    "def calculate_cosine_distances(sentences):\n",
    "    distances = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        embedding_current = sentences[i][\"combined_sentence_embedding\"]\n",
    "        embedding_next = sentences[i + 1][\"combined_sentence_embedding\"]\n",
    "        similarity = cosine_similarity([embedding_current], [embedding_next])[0][0]\n",
    "        distance = 1 - similarity\n",
    "        distances.append(distance)\n",
    "        sentences[i][\"distance_to_next\"] = distance\n",
    "    return distances, sentences\n",
    "\n",
    "def process_financial_document(file_path):\n",
    "    \"\"\"\n",
    "    Processes a financial document, chunks it, and stores the chunks in a FAISS vector store.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the financial document file.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: The FAISS vector store containing the document chunks.\n",
    "    \"\"\"\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # Initialize the breakpoint percentile threshold\n",
    "    breakpoint_percentile_threshold = 95  # set up the initial threshold value\n",
    "    chunk_size_ceiling = 2000\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    parser = Edgar10QParser()\n",
    "    elements = parser.parse(html_content)\n",
    "    \n",
    "    tree_builder = TreeBuilder()\n",
    "    top_level_sections = [item for part in tree_builder.build(elements) for item in part.children]\n",
    "\n",
    "    levels = sorted(\n",
    "        {k.semantic_element.level for k in top_level_sections if isinstance(k.semantic_element, (TopSectionTitle, TitleElement))}\n",
    "    )\n",
    "    level_to_markdown = {level: \"#\" * (i + 2) for i, level in enumerate(levels)}\n",
    "\n",
    "    raw_essay = convert_to_markdown(top_level_sections, level_to_markdown)\n",
    "\n",
    "    single_sentences_list = re.split(r\"(?<=[.#:])\\s+\", raw_essay)\n",
    "    sentences = [{\"sentence\": x, \"index\": i} for i, x in enumerate(single_sentences_list)]\n",
    "\n",
    "    sentences = combine_sentences(sentences)\n",
    "\n",
    "    oaiembeds = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    embeddings = oaiembeds.embed_documents([x[\"combined_sentence\"] for x in sentences])\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence[\"combined_sentence_embedding\"] = embeddings[i]\n",
    "\n",
    "    distances, sentences = calculate_cosine_distances(sentences)\n",
    "\n",
    "    threshold, chunks, chunk_sizes = find_appropriate_threshold(\n",
    "        sentences, distances, breakpoint_percentile_threshold, chunk_size_ceiling\n",
    "    )\n",
    "\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    vectorstore = FAISS.from_documents(documents, oaiembeds)\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item1a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item8. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item10. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item11. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item12. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item13. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item14. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item15. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item16. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the store: 640\n",
      "Document 1:\n",
      "Corporate Information\n",
      "We were incorporated in Delaware in July 2004. We completed our initial public offering in May 2012 and our Class A common stock is currently listed on the Nasdaq Global Select Market under the symbol \"META.\" Our principal executive offices are located at 1 Meta Way, Menlo Park, California 94025, and our telephone number is (650) 543-4800.Meta, the Meta logo, Meta Quest, Meta Horizon, Facebook, FB, Instagram, Oculus, WhatsApp, Reels, and our other registered or common law trademarks, service marks, or trade names appearing in this Annual Report on Form 10-K are the property of Meta Platforms, Inc. or its affiliates.\n",
      "\n",
      "Document 2:\n",
      "# Opinion on Internal Control over Financial Reporting\n",
      "We have audited Meta Platforms, Inc.'s internal control over financial reporting as of December 31, 2023, based on criteria established in Internal Control – Integrated Framework issued by the Committee of Sponsoring Organizations of the Treadway Commission (2013 framework), (the COSO criteria). In our opinion, Meta Platforms, Inc. (the Company) maintained, in all material respects, effective internal control over financial reporting as of December 31, 2023, based on the COSO criteria.We also have audited, in accordance with the standards of the Public Company Accounting Oversight Board (United States) (PCAOB), the consolidated balance sheets of the Company as of December 31, 2023 and 2022, the related consolidated statements of income, comprehensive income, stockholders' equity and cash flows for each of the three years in the period ended December 31, 2023, and the related notes and our report dated February 1, 2024 expressed an unqualified opinion thereon. #\n",
      "\n",
      "Document 3:\n",
      "Business\n",
      "# Overview\n",
      "Our mission is to give people the power to build community and bring the world closer together. All of our products, including our apps, share the vision of helping to bring the metaverse to life. We build technology that helps people connect and share, find communities, and grow businesses. Our products enable people to connect and share with friends and family through mobile devices, personal computers, virtual reality (VR) and mixed reality (MR) headsets, and wearables. We also help people discover and learn about what is going on in the world around them, enable people to share their experiences, ideas, photos and videos, and other activities with audiences ranging from their closest family members and friends to the public at large, and stay connected everywhere by accessing our products. Meta is moving our offerings beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the metaverse, which we believe is the next evolution in social technology. Our vision for the metaverse does not center on any single product, but rather an entire ecosystem of experiences, devices, and new technologies. While the metaverse is in the very early stages of its development, we believe it will become the next computing platform and the future of social interaction. Across our work, we are innovating in artificial intelligence (AI) technologies to build new experiences that help make our platform more social, useful, and immersive.We report financial results for two segments: Family of Apps (FoA) and Reality Labs (RL). Currently, we generate substantially all of our revenue from selling advertising placements on our family of apps to marketers, which is reflected in FoA. Ads on our platform enable marketers to reach people across a range of marketing objectives, such as generating leads or driving awareness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_path = \"data\\\\sec-edgar-filings\\\\META\\\\10-k\\\\2023\\\\primary_document.html\"\n",
    "vs2 = process_financial_document(doc_path)\n",
    "\n",
    "# check how many vectors we have in the store\n",
    "index = vs2.index\n",
    "print(f\"Number of vectors in the store: {index.ntotal}\")\n",
    "\n",
    "# To look at the first 3 vectors, we can retrieve them using their IDs\n",
    "for i in range(min(3, index.ntotal)):\n",
    "    vector = index.reconstruct(i)\n",
    "    # print(f\"Vector {i}: {vector}\")\n",
    "\n",
    "# Retrieve the first k relevant documents in the vector store\n",
    "retriever = vs2.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "query = \" How is the Segment Operating Performance of META company in Australia?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "len(docs)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item1a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item8. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item10. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item11. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item12. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item13. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item14. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item15. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item16. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\n",
    "        r\"data/sec-edgar-filings/AAPL/10-q/2024/Q1/primary_document.html\",\n",
    "        r\"data/sec-edgar-filings/AAPL/10-k/2023/primary_document.html\"\n",
    "    ]\n",
    "    \n",
    "# Process the documents and create the FAISS vector store\n",
    "vectorstore = process_financial_documents(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the store: 173\n",
      "Document 1:\n",
      "Segment Operating Performance\n",
      "The following table shows net sales by reportable segment for 2023, 2022 and 2021 (dollars in millions): ## Americas\n",
      "Americas net sales decreased 4% or $7.1 billion during 2023 compared to 2022 due to lower net sales of iPhone and Mac, partially offset by higher net sales of Services. ## Europe\n",
      "Europe net sales decreased 1% or $824 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Europe net sales, which consisted primarily of lower net sales of Mac and Wearables, Home and Accessories, partially offset by higher net sales of iPhone and Services. ## Greater China\n",
      "Greater China net sales decreased 2% or $1.6 billion during 2023 compared to 2022. The weakness in the renminbi relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Greater China net sales, which consisted primarily of lower net sales of Mac and iPhone. ## Japan\n",
      "Japan net sales decreased 7% or $1.7 billion during 2023 compared to 2022. The weakness in the yen relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Japan net sales, which consisted primarily of lower net sales of iPhone, Wearables, Home and Accessories and Mac. ## Rest of Asia Pacific\n",
      "Rest of Asia Pacific net sales increased 1% or $240 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar had a significantly unfavorable year-over-year impact on Rest of Asia Pacific net sales. The net sales increase consisted of higher net sales of iPhone and Services, partially offset by lower net sales of Mac and iPad.\n",
      "\n",
      "Document 2:\n",
      "Europe includes European countries, as well as India, the Middle East and Africa. Greater China includes China mainland, Hong Kong and Taiwan. Rest of Asia Pacific includes Australia and those Asian countries not included in the Company’s other reportable segments. Although the reportable segments provide similar hardware and software products and similar services, each one is managed separately to better align with the location of the Company’s customers and distribution partners and the unique market dynamics of each geographic region.The Company evaluates the performance of its reportable segments based on net sales and operating income. Net sales for geographic segments are generally based on the location of customers and sales through the Company’s retail stores located in those geographic locations. Operating income for each segment consists of net sales to third parties, related cost of sales, and operating expenses directly attributable to the segment. The information provided to the Company’s chief operating decision maker for purposes of making decisions and assessing segment performance excludes asset information. The following table shows information by reportable segment for 2023, 2022 and 2021 (in millions): A reconciliation of the Company’s segment operating income to the Consolidated Statements of Operations for 2023, 2022 and 2021 is as follows (in millions): (1)Includes corporate marketing expenses, certain share-based compensation expenses, various nonrecurring charges, and other separately managed general and administrative costs.\n",
      "\n",
      "Document 3:\n",
      "Note 13 – Segment Information and Geographic Data\n",
      "The Company manages its business primarily on a geographic basis. The Company’s reportable segments consist of the Americas, Europe, Greater China, Japan and Rest of Asia Pacific. Americas includes both North and South America.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check how many vectors we have in the store\n",
    "index = vectorstore.index\n",
    "print(f\"Number of vectors in the store: {index.ntotal}\")\n",
    "\n",
    "# To look at the first 3 vectors, we can retrieve them using their IDs\n",
    "for i in range(min(3, index.ntotal)):\n",
    "    vector = index.reconstruct(i)\n",
    "    # print(f\"Vector {i}: {vector}\")\n",
    "\n",
    "# Retrieve the first k relevant documents in the vector store\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "query = \" How is the Segment Operating Performance of Apple company in Asia?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "len(docs)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Annotated\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def convert_to_markdown(sections, level_to_markdown):\n",
    "    markdown = \"\"\n",
    "    for section in sections:\n",
    "        if isinstance(section.semantic_element, (TopSectionTitle, TitleElement)):\n",
    "            markdown += f\"{level_to_markdown.get(section.semantic_element.level, '#')} {section.semantic_element.text}\\n\"\n",
    "        elif isinstance(section.semantic_element, TextElement):\n",
    "            markdown += f\"{section.semantic_element.text}\\n\"\n",
    "        for child in section.get_descendants():\n",
    "            if isinstance(child.semantic_element, (TopSectionTitle, TitleElement)):\n",
    "                markdown += f\"{level_to_markdown.get(child.semantic_element.level, '#')} {child.semantic_element.text}\\n\"\n",
    "            elif isinstance(child.semantic_element, TextElement):\n",
    "                markdown += f\"{child.semantic_element.text}\\n\"\n",
    "    return markdown\n",
    "\n",
    "def combine_sentences(sentences, buffer_size=1):\n",
    "    for i in range(len(sentences)):\n",
    "        combined_sentence = \"\"\n",
    "        for j in range(i - buffer_size, i):\n",
    "            if j >= 0:\n",
    "                combined_sentence += sentences[j][\"sentence\"] + \" \"\n",
    "        combined_sentence += sentences[i][\"sentence\"]\n",
    "        for j in range(i + 1, i + 1 + buffer_size):\n",
    "            if j < len(sentences):\n",
    "                combined_sentence += \" \" + sentences[j][\"sentence\"]\n",
    "        sentences[i][\"combined_sentence\"] = combined_sentence\n",
    "    return sentences\n",
    "\n",
    "def calculate_chunk_sizes(sentences, distances, threshold):\n",
    "    breakpoint_distance_threshold = np.percentile(distances, threshold)\n",
    "    indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]\n",
    "    start_index = 0\n",
    "    chunks = []\n",
    "    for index in indices_above_thresh:\n",
    "        end_index = index\n",
    "        group = sentences[start_index : end_index + 1]\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in group])\n",
    "        chunks.append(combined_text)\n",
    "        start_index = index + 1\n",
    "    if start_index < len(sentences):\n",
    "        combined_text = \" \".join([d[\"sentence\"] for d in sentences[start_index:]])\n",
    "        chunks.append(combined_text)\n",
    "    return chunks\n",
    "\n",
    "def find_appropriate_threshold(sentences, distances, initial_threshold, ceiling):\n",
    "    threshold = initial_threshold\n",
    "    while threshold > 0:\n",
    "        chunks = calculate_chunk_sizes(sentences, distances, threshold)\n",
    "        chunk_sizes = [len(chunk.split()) for chunk in chunks]\n",
    "        if max(chunk_sizes) <= ceiling:\n",
    "            break\n",
    "        threshold -= 1\n",
    "    return threshold, chunks, chunk_sizes\n",
    "\n",
    "def calculate_cosine_distances(sentences):\n",
    "    distances = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        embedding_current = sentences[i][\"combined_sentence_embedding\"]\n",
    "        embedding_next = sentences[i + 1][\"combined_sentence_embedding\"]\n",
    "        similarity = cosine_similarity([embedding_current], [embedding_next])[0][0]\n",
    "        distance = 1 - similarity\n",
    "        distances.append(distance)\n",
    "        sentences[i][\"distance_to_next\"] = distance\n",
    "    return distances, sentences\n",
    "\n",
    "def process_financial_documents(file_paths: Annotated[str, \"Comma-separated list of paths to the financial document files.\"]) -> FAISS:\n",
    "    \"\"\"\n",
    "    Processes multiple financial documents, chunks them, and stores the chunks in a single FAISS vector store.\n",
    "\n",
    "    Args:\n",
    "        file_paths (str): Comma-separated list of paths to the financial document files.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: The FAISS vector store containing the document chunks.\n",
    "    \"\"\"\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    breakpoint_percentile_threshold = 95\n",
    "    chunk_size_ceiling = 2000\n",
    "    all_chunks = []\n",
    "    embeddings_engine = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    \n",
    "    paths = file_paths.split(',')\n",
    "    for file_path in paths:\n",
    "        with open(file_path.strip(), \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "        \n",
    "        parser = Edgar10QParser()\n",
    "        elements = parser.parse(html_content)\n",
    "        \n",
    "        tree_builder = TreeBuilder()\n",
    "        top_level_sections = [item for part in tree_builder.build(elements) for item in part.children]\n",
    "\n",
    "        levels = sorted(\n",
    "            {k.semantic_element.level for k in top_level_sections if isinstance(k.semantic_element, (TopSectionTitle, TitleElement))}\n",
    "        )\n",
    "        level_to_markdown = {level: \"#\" * (i + 2) for i, level in enumerate(levels)}\n",
    "\n",
    "        raw_essay = convert_to_markdown(top_level_sections, level_to_markdown)\n",
    "\n",
    "        single_sentences_list = re.split(r\"(?<=[.#:])\\s+\", raw_essay)\n",
    "        sentences = [{\"sentence\": x, \"index\": i} for i, x in enumerate(single_sentences_list)]\n",
    "\n",
    "        sentences = combine_sentences(sentences)\n",
    "\n",
    "        embeddings = embeddings_engine.embed_documents([x[\"combined_sentence\"] for x in sentences])\n",
    "\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            sentence[\"combined_sentence_embedding\"] = embeddings[i]\n",
    "\n",
    "        distances, sentences = calculate_cosine_distances(sentences)\n",
    "\n",
    "        threshold, chunks, chunk_sizes = find_appropriate_threshold(\n",
    "            sentences, distances, breakpoint_percentile_threshold, chunk_size_ceiling\n",
    "        )\n",
    "\n",
    "        document_id = os.path.basename(file_path)\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append(Document(page_content=chunk, metadata={\"document_id\": document_id}))\n",
    "\n",
    "    vectorstore = FAISS.from_documents(all_chunks, embeddings_engine)\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item1a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item7a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item8. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part2item9a. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item10. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item11. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item12. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item13. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part3item14. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item15. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n",
      "c:\\Users\\goldr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sec_parser\\processing_engine\\core.py:153: UserWarning: Invalid section type for part1item16. Defaulting to InvalidTopSectionIn10Q.\n",
      "  elements = step.process(elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the store: 1373\n",
      "Document 1:\n",
      "Corporate Information\n",
      "We were incorporated in Delaware in July 2004. We completed our initial public offering in May 2012 and our Class A common stock is currently listed on the Nasdaq Global Select Market under the symbol \"META.\" Our principal executive offices are located at 1 Meta Way, Menlo Park, California 94025, and our telephone number is (650) 543-4800.Meta, the Meta logo, Meta Quest, Meta Horizon, Facebook, FB, Instagram, Oculus, WhatsApp, Reels, and our other registered or common law trademarks, service marks, or trade names appearing in this Annual Report on Form 10-K are the property of Meta Platforms, Inc. or its affiliates.\n",
      "\n",
      "Document 2:\n",
      "# Opinion on Internal Control over Financial Reporting\n",
      "We have audited Meta Platforms, Inc.'s internal control over financial reporting as of December 31, 2023, based on criteria established in Internal Control – Integrated Framework issued by the Committee of Sponsoring Organizations of the Treadway Commission (2013 framework), (the COSO criteria). In our opinion, Meta Platforms, Inc. (the Company) maintained, in all material respects, effective internal control over financial reporting as of December 31, 2023, based on the COSO criteria.We also have audited, in accordance with the standards of the Public Company Accounting Oversight Board (United States) (PCAOB), the consolidated balance sheets of the Company as of December 31, 2023 and 2022, the related consolidated statements of income, comprehensive income, stockholders' equity and cash flows for each of the three years in the period ended December 31, 2023, and the related notes and our report dated February 1, 2024 expressed an unqualified opinion thereon. #\n",
      "\n",
      "Document 3:\n",
      "Business\n",
      "# Overview\n",
      "Our mission is to give people the power to build community and bring the world closer together. All of our products, including our apps, share the vision of helping to bring the metaverse to life. We build technology that helps people connect and share, find communities, and grow businesses. Our products enable people to connect and share with friends and family through mobile devices, personal computers, virtual reality (VR) and mixed reality (MR) headsets, and wearables. We also help people discover and learn about what is going on in the world around them, enable people to share their experiences, ideas, photos and videos, and other activities with audiences ranging from their closest family members and friends to the public at large, and stay connected everywhere by accessing our products. Meta is moving our offerings beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the metaverse, which we believe is the next evolution in social technology. Our vision for the metaverse does not center on any single product, but rather an entire ecosystem of experiences, devices, and new technologies. While the metaverse is in the very early stages of its development, we believe it will become the next computing platform and the future of social interaction. Across our work, we are innovating in artificial intelligence (AI) technologies to build new experiences that help make our platform more social, useful, and immersive.We report financial results for two segments: Family of Apps (FoA) and Reality Labs (RL). Currently, we generate substantially all of our revenue from selling advertising placements on our family of apps to marketers, which is reflected in FoA. Ads on our platform enable marketers to reach people across a range of marketing objectives, such as generating leads or driving awareness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_path = \"data/sec-edgar-filings/META/10-k/2023/primary_document.html,data/sec-edgar-filings/META/10-q/2024/Q2/primary_document.html,data/sec-edgar-filings/META/10-q/2023/Q3/primary_document.html\"\n",
    "vs2 = process_financial_documents(doc_path)\n",
    "\n",
    "# check how many vectors we have in the store\n",
    "index = vs2.index\n",
    "print(f\"Number of vectors in the store: {index.ntotal}\")\n",
    "\n",
    "# To look at the first 3 vectors, we can retrieve them using their IDs\n",
    "for i in range(min(3, index.ntotal)):\n",
    "    vector = index.reconstruct(i)\n",
    "    # print(f\"Vector {i}: {vector}\")\n",
    "\n",
    "# Retrieve the first k relevant documents in the vector store\n",
    "retriever = vs2.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "query = \" How is the Segment Operating Performance of META company in Australia?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n",
    "len(docs)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
